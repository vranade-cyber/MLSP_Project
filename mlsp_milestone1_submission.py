# -*- coding: utf-8 -*-
"""MLSP_Milestone1_Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VaFy_uXgS4sK8a_eOULDblU3utt94Q3x
"""

!apt-get install texlive texlive-xetex texlive-latex-extra pandoc
!pip install pypandoc

from google.colab import drive
drive.mount('/content/drive/')

!jupyter nbconvert --to PDF "/content/drive/MyDrive/Colab Notebooks/Coding Section: MLSP HW3.ipynb"

!pip install yfinance

"""Download all the stocks data from yfinance"""

import os, contextlib
import pandas as pd
import yfinance as yf

if not os.path.exists("stocks data"):
    os.mkdir("stocks data")

url = "https://en.wikipedia.org/wiki/NASDAQ-100#Components"
html = pd.read_html(url, header=0)
series = html[4]["Ticker"]
symbols = series.to_list()

with open(os.devnull, "w") as devnull:
    with contextlib.redirect_stdout(devnull):
        for i, symbol in enumerate(symbols):
            data = yf.download(symbol, period="max")["Close"]
            data.to_csv("stocks data/{}.csv".format(symbol))

"""Sample plot of TESLA closing prices"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib as plt
import yfinance as yf
import plotly.express as px
# %matplotlib inline

tsla = yf.download("TSLA", period="MAX", Interval="1d")
tsla_close = px.line(
    tsla["Close"],
    title="Tesla Closing Price",
    color_discrete_map={"Close": "green"},
    width=800,
    height=800,
)
tsla_close.show()

"""Check and remove any NULL values"""

df = tsla.Close
tesla_closing_prices = df.dropna()
print(f"Nulls: {tesla_closing_prices.isnull().sum()}")

"""Sample View of Data"""

df.head(10)

df.tail(10)

"""Before running the experiement for all stocks, we show a demo using TESLA closing prices

Determine order for sample ARIMA model

ACF to determine order of MA model (q)
"""

from datetime import datetime
from statsmodels.tsa.stattools import acf , pacf
from statsmodels.graphics.tsaplots import plot_acf
import matplotlib.pyplot as plt

plt.style.use('ggplot')
plot_acf(tesla_closing_prices, lags=10)
plt.ylabel("Correlation coefficient");
plt.xlabel('Lag at k');
plt.title('ACF');

"""Partial ACF can determine order of AR model (p)"""

from statsmodels.graphics.tsaplots import plot_pacf
plot_pacf(tesla_closing_prices, lags=10)
plt.title("Partial ACF");
plt.xlabel("Lag at k");
plt.ylabel("Correlation Coefficient");

"""ADF Test - We check the stationarity and difference it if not stationary. If the differencing is done, we need to compute p and q for the differenced time series"""

from statsmodels.tsa.stattools import adfuller


def stationarity_test(time_series):
    df_test = adfuller(time_series)

    print("{:25s} {:.6f}".format("\033[1m ADF Statistics ", df_test[0]))
    print("{:25s} {:.6f}\n".format("\033[1m p-value ", df_test[1]))

    if df_test[0] > df_test[4]["5%"]:
        print("\033[36m\033[1mCan not Reject H0 - Non-stationary time series\n")
    else:
        print("\033[36m\033[1mCan Reject H0 - Stationary time series\n")

    a = pd.DataFrame([df_test[4]], index=["Critical Values"])
    return a

stationarity_test(tesla_closing_prices)

"""Differencing"""

tesla_price1 = tesla_closing_prices.diff(1).bfill() # First order differencing
plt.xlabel('Years')
plt.ylabel('Price')    
plt.title('Convert non-stationary time series to stationary time series by differencing ')
plt.plot(tesla_price1, 'b-.')

stationarity_test(tesla_price1)

"""Stationary after first difference. Value of d = 1"""

plt.xlabel('Years')
plt.ylabel('Price')    
plt.title('Convert Non Stationary Data to Stationary Data using Differencing ')
plt.plot(tesla_price1, 'b-.')

"""Determine the new AR Order (p)"""

plot_pacf(tesla_price1,lags=20)
plt.xlabel('Lags')
plt.ylabel("Correlation Coefficient")
plt.title('Partial Autocorrelation Function')

"""p = 2

Determine the new MA Order (q)
"""

plot_acf(tesla_price1, lags=20)
plt.xlabel('Lags')
plt.ylabel("Correlation Coefficient")
plt.title('Autocorrelation Function')

"""q = 1

Prediction for the next 5 days using TESLA time series
"""

train = tesla_closing_prices[:-5]
test =  tesla_closing_prices[-5:]

!pip install statsmodels==0.11.0

from statsmodels.tsa.arima_model import ARIMA
import warnings

warnings.filterwarnings("ignore")

model = ARIMA(train, order=(2, 1, 1))
fitted = model.fit(disp=0)
forecast, se, conf_int = fitted.forecast(5, alpha=0.05)
f_series = pd.Series(forecast, index=test.index)
lower_bound = pd.Series(conf_int[:, 0], index=test.index)
upper_bound = pd.Series(conf_int[:, 1], index=test.index)

# Plot
plt.figure(figsize=(10, 7), dpi=100)
plt.plot(train, label="training")
plt.plot(test, "g:", label="actual")
plt.plot(f_series, "b--", label="forecast")
plt.fill_between(lower_bound.index, lower_bound, upper_bound, color="b", alpha=0.2)
plt.plot(lower_bound, color="y", label="Confidence Interval Upper bound ")
plt.plot(upper_bound, color="y", label="Confidence Interval Lower bound ")
plt.title("Forecast vs Actual")
plt.legend(loc="upper left", fontsize=8)
plt.show()

"""Clear plot with more values in the forecast"""

train = tesla_closing_prices[:-200]
test =  tesla_closing_prices[-200:]

from statsmodels.tsa.arima_model import ARIMA
import warnings

warnings.filterwarnings("ignore")

model = ARIMA(train, order=(2, 1, 1))
fitted = model.fit(disp=0)
forecast, se, conf_int = fitted.forecast(200, alpha=0.05)
f_series = pd.Series(forecast, index=test.index)
lower_bound = pd.Series(conf_int[:, 0], index=test.index)
upper_bound = pd.Series(conf_int[:, 1], index=test.index)

# Plot
plt.figure(figsize=(10, 7), dpi=100)
plt.plot(train, label="training")
plt.plot(test, "g:", label="actual")
plt.plot(f_series, "b--", label="forecast")
plt.fill_between(lower_bound.index, lower_bound, upper_bound, color="b", alpha=0.2)
plt.plot(lower_bound, color="y", label="Confidence Interval Upper bound ")
plt.plot(upper_bound, color="y", label="Confidence Interval Lower bound ")
plt.title("Forecast vs ARIMA predictions")
plt.legend(loc="upper left", fontsize=8)
plt.show()

"""Not too bad!

## Let's check out SARIMAX
"""

!pip install pandas==1.1.3

!pip3 uninstall statsmodels

!pip3 install numpy scipy patsy

!pip3 install statsmodels

import statsmodels.api as sm
import yfinance as yf
import warnings
warnings.filterwarnings('ignore')

tsla_stock = yf.Ticker("TSLA")
tsla_historical_prices = tsla_stock.history(period="10y")
tsla_closing_prices_df = tsla_historical_prices[[ 'Close']]
tesla_closing_prices = tsla_closing_prices_df[ 'Close']

train = tesla_closing_prices[:-200]
test =  tesla_closing_prices[-200:]
model=sm.tsa.statespace.SARIMAX(train, order=(2, 1, 1), seasonal_order=(1,1,1,12))

results=model.fit()

# Commented out IPython magic to ensure Python compatibility.
import warnings
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

warnings.filterwarnings("ignore")

forcast_sarimax = results.predict(start=2319, end=2518, dynamic=True).to_numpy()
f_series = pd.Series(forcast_sarimax, index=test.index)
plt.figure(figsize=(10, 7), dpi=100)
plt.plot(train, label="training")
plt.plot(test, "g:", label="actual")
plt.plot(f_series, "b", label="forecast")

plt.title("Forecast vs Actual SARIMAX")
plt.legend(loc="upper left", fontsize=8)
plt.show()

"""We see that both models are not very accurate, but we will use ARIMA for the rest of the notebook demonstration

## FINAL DEMO RUN
"""

from statsmodels.tsa.stattools import adfuller

def stationarity_test(time_series):
  df_test = adfuller(time_series)
  if df_test[0] > df_test[4]["5%"]:
    return False
  else:
    return True

import warnings
warnings.filterwarnings('ignore')

"""## Test Run Without Grid Search"""

from statsmodels.tsa.arima_model import ARIMA

final_forecasts = {}
p = 2
q = 1
prediction_length = 5
d = {}

for symbol in symbols:
    stock = yf.download(symbol, period="MAX", Interval="1d", verbose=False)
    closing_prices = stock.Close.dropna()
    original_cp = closing_prices
    assert closing_prices.isnull().sum() == 0
    d_counter = 0
    while not stationarity_test(closing_prices):
        closing_prices = closing_prices.diff(1).bfill()
        d_counter += 1
    d[symbol] = d_counter

    train_closing_prices = original_cp[:-prediction_length]
    test_closing_prices = original_cp[-prediction_length:]
    model = ARIMA(train_closing_prices, order=(2, 1, 1))
    try:
        model_fit = model.fit(disp=0)
    except Exception as e:
        print(f"An exception occurred")
        continue

    forecast, se, conf_int = model_fit.forecast(prediction_length, alpha=0.05)
    final_forecasts[symbol] = forecast

import numpy as np
np.save('forecasts_companies.npy', final_forecasts)

"""## Grid Search AWAY!!!"""

from sklearn.metrics import mean_squared_error
from math import sqrt


def evaluate_arima_model(train, test, arima_order):
    history = [x for x in train]
    predictions = list()
    for t in range(len(test)):
        model = ARIMA(history, order=arima_order)
        model_fit = model.fit()
        yhat = model_fit.forecast()[0]
        predictions.append(yhat)
        history.append(test[t])

    rmse = sqrt(mean_squared_error(test, predictions))
    return rmse

def grid_search(
    train,
    test,
    symbol,
    p_values=[1, 2, 6, 10],
    q_values=list(range(0, 3)),
    d_values=[1],
):
    best_score, best_cfg = float("inf"), None
    for p in p_values:
        for d in d_values:
            for q in q_values:
                order = (p, d, q)
                try:
                    rmse = evaluate_arima_model(train, test, order)
                    if rmse < best_score:
                        best_score, best_cfg = rmse, order
                except:
                    continue
    print("Best ARIMA%s RMSE=%.3f: %s" % (best_cfg, best_score, symbol))
    return best_cfg

from statsmodels.tsa.arima_model import ARIMA

final_forecasts = {}
d_dict = {}
prediction_length = 5

for symbol in symbols:
    stock = yf.download(symbol, period="MAX", Interval="1d", verbose=False)
    closing_prices = stock.Close.dropna()
    original_cp = closing_prices
    assert closing_prices.isnull().sum() == 0
    d_counter = 0
    while not stationarity_test(closing_prices):
        closing_prices = closing_prices.diff(1).bfill()
        d_counter += 1
    d_dict[symbol] = d_counter

    train_closing_prices = original_cp[:-prediction_length]
    test_closing_prices = original_cp[-prediction_length:]
    p, d, q = grid_search(train_closing_prices, test_closing_prices, symbol)
    model = ARIMA(train_closing_prices, order=(p, d_dict[symbol], q))

    try:
        model_fit = model.fit(disp=0)
    except Exception as e:
        print(f"An exception occurred")
        continue

    forecast, se, conf_int = model_fit.forecast(prediction_length, alpha=0.05)
    final_forecasts[symbol] = forecast

"""We use this forecasts array. Grid search is slow on colab CPU, so we have run it on a faster CPU to get the forecasts

Loading the forecasts array
"""

import numpy as np

data = np.load('/content/forecasts.npy', allow_pickle=True)
stock_predictions = []
for k, v in data.item().items():
  stock_predictions.append(v)

stock_predictions = np.array(stock_predictions)

stock_predictions.shape

"""Using our predictions over the next 5 days, we have now come up with an optimized strategy to make purchases. We are close to cracking it, but will have decent profits towards the end"""

class Node:
    def __init__(self, val, pred, ID, path):
        self.val = val
        self.pred = pred
        self.ID = ID
        self.path = path


class Strat_predictor:
    def __init__(self, arr):
        self.data = arr

    def create_row(self, arr):
        (n,) = np.shape(arr)
        k = n * (n - 1) // 2

        grid = np.zeros((k, 1))
        count = 0
        for i in range(n):
            for j in range(i + 1, n):
                grid[count] = (arr[j] - arr[i]) / arr[i]
                count += 1
        grid = grid.reshape(1, k)
        return grid

    def create_grid(self, arr):
        m, n = np.shape(arr)
        k = n * (n - 1) // 2
        delta = []
        for i in range(m):
            delt = self.create_row(arr[i])
            delta.append(delt)

        delta2 = np.array((delta)).reshape(m, k)
        return delta2, n

    def create_matrix(self):
        self.table, num_nodes = self.create_grid(self.data)
        self.t = np.array(np.max(self.table, axis=0))
        self.adj_graph = np.full((num_nodes, num_nodes), None)
        counter = num_nodes - 1

        start = 0
        for i in range(num_nodes - 1):
            self.adj_graph[i][i + 1 :] = self.t[start : start + counter]
            start = start + counter
            counter -= 1

        for i in range(num_nodes):
            self.adj_graph[i][i] = 0

        self.adj_graph = self.adj_graph.T
        # print(self.adj_graph)
        return num_nodes

    def setup_graph(self):
        self.num_nodes = self.create_matrix()
        self.nodes = []
        for i in range(self.num_nodes):
            self.nodes.append(Node(0, list(range(i)), i, []))

    def get_strat(self):
        self.setup_graph()
        gstack = []
        stack = []
        flag = (0, 0)
        for i, j in enumerate(self.nodes):
            row = self.adj_graph[i]
            for p in j.pred:
                value = self.nodes[p].val + row[p]
                if value > j.val:
                    flag = (p, i)

                j.val = max(j.val, value)

            if j == 0:
                j.path = [0]
            else:
                s, e = flag
                j.path = self.nodes[s].path + [e]
            gstack.append((flag))

    def check(self):
        self.get_strat()
        best_node_val = 0
        for k in range(self.num_nodes):
            vals = self.nodes[k].val
            if vals > best_node_val:
                best_node_index = k
            best_node_val = max(best_node_val, vals)

        best_node_path = self.nodes[best_node_index].path
        p_path = best_node_path

        path = list(zip(p_path[:-1], p_path[1:]))
        return path

    def predict(self, path):
        self.strat = []
        for buy_day, sell_day in path:
            stock_val = self.adj_graph[sell_day][buy_day]
            stock, delta = np.where(self.table == stock_val)
            self.strat.append(((stock), (buy_day, sell_day)))
        return self.strat

    def display(self):
        money = 1000
        for stock, (b, s) in self.strat:
            index = stock[0]
            print(
                "Buy Stock with ID",
                index,
                "at end of day",
                b,
                "and sell at end of day",
                s,
            )
            stock_num = money / self.data[index][b]
            money = stock_num * self.data[index][s]
        print("\n\n\nProfit made on investment of 1000$ is: $", money - 1000)

import numpy as np

data = np.load('/content/forecasts.npy', allow_pickle=True)
stocks_data = []
for k, v in data.item().items():
  stocks_data.append(v)

stocks_data = np.array(stocks_data)

h = Strat_predictor(stocks_data)
y = h.check()
strat = h.predict(y)
h.display()